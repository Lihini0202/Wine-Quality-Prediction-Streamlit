{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swLrZcz6gYuO"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "5833kHKVgTVI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ9RH78OhX-V",
        "outputId": "91cbd645-c290-4468-8e69-d70db24ad817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest Classifier...\n",
            "\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.72      0.75       321\n",
            "           1       0.84      0.90      0.87       624\n",
            "           2       1.00      0.43      0.60        35\n",
            "\n",
            "    accuracy                           0.82       980\n",
            "   macro avg       0.87      0.68      0.74       980\n",
            "weighted avg       0.82      0.82      0.82       980\n",
            "\n",
            "Random Forest Accuracy: 0.8214285714285714\n",
            "Random Forest Cross-Validation Accuracy (5-fold): 0.7156 (+/- 0.0266)\n",
            "\n",
            "Training Logistic Regression...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.47      0.54       321\n",
            "           1       0.73      0.86      0.79       624\n",
            "           2       0.00      0.00      0.00        35\n",
            "\n",
            "    accuracy                           0.70       980\n",
            "   macro avg       0.45      0.44      0.44       980\n",
            "weighted avg       0.67      0.70      0.68       980\n",
            "\n",
            "Logistic Regression Accuracy: 0.7030612244897959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Cross-Validation Accuracy (5-fold): 0.7015 (+/- 0.0263)\n",
            "\n",
            "✅ Model (Random Forest) trained and saved as model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')\n",
        "\n",
        "# Clean column names (remove quotes and spaces)\n",
        "df.columns = df.columns.str.replace('\\\"', '').str.strip()\n",
        "\n",
        "# Convert quality into categories\n",
        "df['quality_label'] = pd.cut(df['quality'],\n",
        "                             bins=[0, 5, 7, 10],\n",
        "                             labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "# Encode labels\n",
        "df['quality_label'] = df['quality_label'].map({'Low': 0, 'Medium': 1, 'High': 2})\n",
        "\n",
        "X = df.drop(['quality', 'quality_label'], axis=1)\n",
        "y = df['quality_label']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Model 1: Random Forest Classifier ---\n",
        "print(\"Training Random Forest Classifier...\")\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "print(\"\\nRandom Forest Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "\n",
        "# Cross-validation for Random Forest\n",
        "rf_cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy')\n",
        "print(f\"Random Forest Cross-Validation Accuracy (5-fold): {np.mean(rf_cv_scores):.4f} (+/- {np.std(rf_cv_scores):.4f})\")\n",
        "\n",
        "# --- Model 2: Logistic Regression ---\n",
        "print(\"\\nTraining Logistic Regression...\")\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42) # Increased max_iter for convergence\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "print(\"\\nLogistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "\n",
        "# Cross-validation for Logistic Regression\n",
        "lr_cv_scores = cross_val_score(lr_model, X, y, cv=5, scoring='accuracy')\n",
        "print(f\"Logistic Regression Cross-Validation Accuracy (5-fold): {np.mean(lr_cv_scores):.4f} (+/- {np.std(lr_cv_scores):.4f})\")\n",
        "\n",
        "\n",
        "# Save the best-performing model (Random Forest in this case)\n",
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(rf_model, f)\n",
        "\n",
        "print(\"\\n✅ Model (Random Forest) trained and saved as model.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1ZEAU1mmHLk",
        "outputId": "4fbfbe63-7c32-44b6-cc04-1be508efefe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.47.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.47.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "changed 22 packages in 2s\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0KRequirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.12)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!npm install -g localtunnel\n",
        "!pip install pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "# Load and prepare the dataset\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')\n",
        "df['quality_label'] = pd.cut(df['quality'], bins=[0, 5, 7, 10], labels=['Low', 'Medium', 'High'])\n",
        "df['quality_label'] = df['quality_label'].map({'Low': 0, 'Medium': 1, 'High': 2})\n",
        "X = df.drop(['quality', 'quality_label'], axis=1)\n",
        "y = df['quality_label']\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Save the model in current directory as model.pkl\n",
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "print(\"✅ Model trained and saved as model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjdSHPQ5Z3uN",
        "outputId": "a4a9fd9d-f813-4826-aceb-86b6bef63409"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model trained and saved as model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIo7Ys_-sLmj",
        "outputId": "7ec3b441-7d02-49ff-e849-691126c32d84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')\n",
        "df.columns = df.columns.str.replace('\\\"', '').str.strip()\n",
        "df['quality_label'] = pd.cut(df['quality'], bins=[0, 5, 7, 10], labels=['Low', 'Medium', 'High'])\n",
        "df['quality_label'] = df['quality_label'].map({'Low': 0, 'Medium': 1, 'High': 2})\n",
        "X = df.drop(['quality', 'quality_label'], axis=1)\n",
        "y = df['quality_label']\n",
        "\n",
        "# Train-test split (needed here for evaluation metrics in app)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load model (the best model, which is Random Forest in this case)\n",
        "with open(\"model.pkl\", \"rb\") as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# Re-train Logistic Regression here for comparison in the app, or load if saved\n",
        "\n",
        "lr_model_for_app = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_model_for_app.fit(X_train, y_train)\n",
        "y_pred_lr_app = lr_model_for_app.predict(X_test)\n",
        "lr_accuracy = accuracy_score(y_test, y_pred_lr_app)\n",
        "\n",
        "# Get predictions for the main model (Random Forest) for evaluation in the app\n",
        "y_pred_main_model = model.predict(X_test)\n",
        "\n",
        "# Layout\n",
        "st.set_page_config(page_title=\"Wine Quality Predictor\", layout=\"wide\")\n",
        "st.title(\"🍇 Wine Quality App\")\n",
        "\n",
        "# Tabs\n",
        "tabs = st.tabs([\n",
        "    \"🏠 Home\", \"🔍 Explore Data\", \"📊 Visualizations\", \"🎯 Predict Quality\",\n",
        "    \"📁 Upload CSV\", \"📂 Model Info\", \"🧪 Model Comparison\", \"📜 Feature Guide\"\n",
        "])\n",
        "\n",
        "# Tab 1: Home\n",
        "with tabs[0]:\n",
        "    st.markdown(\"\"\"\n",
        "    <h1 style='text-align: center; font-size: 60px;'>🍷 Welcome to the Wine Quality Predictor App</h1>\n",
        "    <h4 style='text-align: center; color: gray;'>Machine Learning for Wine Lovers 🍇</h4>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    st.image(\"https://c.tenor.com/FW6_Tfz5NpcAAAAd/wine.gif\", use_container_width=True)\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    <div style=\"background-color:#white; padding:20px; border-radius:10px; border:1px solid #e0c097\">\n",
        "        <h4>📌 What You Can Do:</h4>\n",
        "        <ul style=\"line-height: 1.8;\">\n",
        "            <li>🔍 Explore white wine data</li>\n",
        "            <li>📊 Visualize relationships and distributions</li>\n",
        "            <li>🎯 Predict wine quality using a trained model</li>\n",
        "            <li>📁 Upload your own CSV for predictions</li>\n",
        "            <li>📖 Learn about wine features</li>\n",
        "        </ul>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"- **Dataset:** [UCI White Wine Quality Dataset](https://archive.ics.uci.edu/ml/datasets/Wine+Quality)\")\n",
        "    st.markdown(\"- **Main Model:** Random Forest Classifier\")\n",
        "\n",
        "\n",
        "# Tab 2: Explore Data\n",
        "with tabs[1]:\n",
        "    st.header(\"🔍 Explore Dataset\")\n",
        "    if st.checkbox(\"Show Raw Data\"):\n",
        "        st.write(df.head())\n",
        "    if st.checkbox(\"Show Summary Statistics\"):\n",
        "        st.write(df.describe())\n",
        "    st.subheader(\"Correlation Heatmap\")\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# Tab 3: Visualizations\n",
        "with tabs[2]:\n",
        "    st.header(\"📊 Visualizations\")\n",
        "    st.subheader(\"Distribution Plot\")\n",
        "    dist_col = st.selectbox(\"Choose a feature\", df.columns[:-2])\n",
        "    fig1, ax1 = plt.subplots()\n",
        "    sns.histplot(df[dist_col], kde=True, ax=ax1, color=\"teal\")\n",
        "    st.pyplot(fig1)\n",
        "\n",
        "    st.subheader(\"Boxplot vs Wine Quality\")\n",
        "    box_col = st.selectbox(\"Select feature for boxplot\", df.columns[:-2], index=10)\n",
        "    fig2, ax2 = plt.subplots()\n",
        "    sns.boxplot(x=\"quality_label\", y=box_col, data=df, ax=ax2)\n",
        "    st.pyplot(fig2)\n",
        "\n",
        "# Tab 4: Predict Quality\n",
        "with tabs[3]:\n",
        "    st.header(\"🎯 Predict Wine Quality\")\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        fa = st.slider(\"Fixed Acidity\", 4.0, 16.0, 7.0)\n",
        "        va = st.slider(\"Volatile Acidity\", 0.1, 1.5, 0.3)\n",
        "        ca = st.slider(\"Citric Acid\", 0.0, 1.0, 0.3)\n",
        "        rs = st.slider(\"Residual Sugar\", 0.5, 15.0, 5.0)\n",
        "        cl = st.slider(\"Chlorides\", 0.01, 0.2, 0.045)\n",
        "    with col2:\n",
        "        fsd = st.slider(\"Free Sulfur Dioxide\", 2.0, 80.0, 30.0)\n",
        "        tsd = st.slider(\"Total Sulfur Dioxide\", 9.0, 300.0, 115.0)\n",
        "        dens = st.slider(\"Density\", 0.987, 1.005, 0.994)\n",
        "        ph = st.slider(\"pH\", 2.5, 4.5, 3.2)\n",
        "        sul = st.slider(\"Sulphates\", 0.2, 1.5, 0.5)\n",
        "        alc = st.slider(\"Alcohol\", 8.0, 14.0, 10.0)\n",
        "    if st.button(\"Predict\"):\n",
        "        input_df = pd.DataFrame([{\"fixed acidity\": fa, \"volatile acidity\": va, \"citric acid\": ca, \"residual sugar\": rs,\n",
        "                                  \"chlorides\": cl, \"free sulfur dioxide\": fsd, \"total sulfur dioxide\": tsd,\n",
        "                                  \"density\": dens, \"pH\": ph, \"sulphates\": sul, \"alcohol\": alc}])\n",
        "        pred = model.predict(input_df)[0]\n",
        "        label = {0: \"Low\", 1: \"Medium\", 2: \"High\"}[pred]\n",
        "        st.success(f\"Predicted Wine Quality: **{label}**\")\n",
        "\n",
        "    st.metric(\"Main Model (Random Forest) Accuracy on Test Set\", f\"{accuracy_score(y_test, y_pred_main_model):.2%}\")\n",
        "\n",
        "    st.subheader(\"Model Performance Details\")\n",
        "    st.text(\"Classification Report (Random Forest on Test Set):\")\n",
        "    st.code(classification_report(y_test, y_pred_main_model, target_names=['Low', 'Medium', 'High']))\n",
        "\n",
        "    st.text(\"Confusion Matrix (Random Forest on Test Set):\")\n",
        "    fig_cm, ax_cm = plt.subplots(figsize=(8, 6))\n",
        "    cmp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_main_model), display_labels=['Low', 'Medium', 'High'])\n",
        "    cmp.plot(ax=ax_cm, cmap='Blues')\n",
        "    plt.title('Confusion Matrix for Random Forest Classifier')\n",
        "    st.pyplot(fig_cm)\n",
        "\n",
        "\n",
        "# Tab 5: Upload CSV\n",
        "with tabs[4]:\n",
        "    st.header(\"📁 Upload Your Own Wine Data\")\n",
        "    uploaded_file = st.file_uploader(\"Upload a CSV file\", type=\"csv\")\n",
        "    if uploaded_file:\n",
        "        user_df = pd.read_csv(uploaded_file)\n",
        "        st.write(\"Preview:\", user_df.head())\n",
        "        try:\n",
        "            # Ensure columns match training data\n",
        "            missing_cols = set(X.columns) - set(user_df.columns)\n",
        "            if missing_cols:\n",
        "                st.error(f\"Error: Missing columns in uploaded CSV: {', '.join(missing_cols)}. Please ensure your CSV has all required features.\")\n",
        "            else:\n",
        "                # Reorder columns to match the training data's column order\n",
        "                user_df_processed = user_df[X.columns]\n",
        "                preds = model.predict(user_df_processed)\n",
        "                user_df[\"Predicted Quality\"] = [ {0: \"Low\", 1: \"Medium\", 2: \"High\"}[p] for p in preds ]\n",
        "                st.success(\"Predictions complete!\")\n",
        "                st.write(user_df)\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error making predictions. Check column names and formats. Details: {e}\")\n",
        "\n",
        "# Tab 6: Model Info\n",
        "with tabs[5]:\n",
        "    st.header(\"📂 Model Details & Download\")\n",
        "    st.markdown(\"**Main Model:** Random Forest Classifier (n_estimators=100, random_state=42)\")\n",
        "    st.markdown(\"**Classes:** Low, Medium, High\")\n",
        "    st.write(\"The `model.pkl` file contains the trained Random Forest Classifier.\")\n",
        "    with open(\"model.pkl\", \"rb\") as f:\n",
        "        st.download_button(\"Download model.pkl\", f.read(), file_name=\"model.pkl\")\n",
        "\n",
        "# Tab 7: Model Comparison\n",
        "with tabs[6]:\n",
        "    st.header(\"🧪 Model Comparison\")\n",
        "    # Dynamically show accuracies of trained models\n",
        "    rf_accuracy_app = accuracy_score(y_test, model.predict(X_test)) # Accuracy of the main RF model\n",
        "\n",
        "    models_comparison = {\n",
        "        \"Random Forest\": rf_accuracy_app,\n",
        "        \"Logistic Regression\": lr_accuracy # Use the actual calculated LR accuracy\n",
        "    }\n",
        "\n",
        "    st.markdown(f\"**Random Forest Accuracy:** `{rf_accuracy_app:.2%}`\")\n",
        "    st.markdown(f\"**Logistic Regression Accuracy:** `{lr_accuracy:.2%}`\")\n",
        "\n",
        "    fig3, ax3 = plt.subplots()\n",
        "    sns.barplot(x=list(models_comparison.values()), y=list(models_comparison.keys()), ax=ax3, palette='viridis')\n",
        "    ax3.set_xlim(0, 1)\n",
        "    ax3.set_xlabel(\"Accuracy\")\n",
        "    ax3.set_title(\"Model Accuracy Comparison on Test Set\")\n",
        "    st.pyplot(fig3)\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.subheader(\"Why Random Forest was chosen:\")\n",
        "    st.write(\"Random Forest models generally offer high accuracy, handle non-linear relationships well, and are less prone to overfitting compared to single decision trees.\")\n",
        "    st.write(\"Based on our evaluation, the Random Forest model performed better than Logistic Regression in classifying wine quality.\")\n",
        "\n",
        "\n",
        "# Tab 8: Feature Guide\n",
        "with tabs[7]:\n",
        "    st.header(\"📜 Feature Reference Guide\")\n",
        "    st.markdown(\"\"\"\n",
        "    - **Fixed Acidity**: Represents the non-volatile acids in wine. Tartaric acid is a major fixed acid. Higher levels can indicate a more tart taste.\n",
        "    - **Volatile Acidity**: Primarily acetic acid, which can give wine a vinegar-like taste if too high. It's an indicator of spoilage.\n",
        "    - **Citric Acid**: A small amount of citric acid adds 'freshness' and flavor to wines.\n",
        "    - **Residual Sugar**: The amount of sugar remaining after fermentation. Sweetness in wine is directly related to this.\n",
        "    - **Chlorides**: The amount of salt in the wine. Higher levels can indicate a salty taste.\n",
        "    - **Free Sulfur Dioxide**: The unreactive form of SO2, which helps prevent microbial growth and oxidation in wine.\n",
        "    - **Total Sulfur Dioxide**: The total amount of SO2 (free and bound forms) in the wine. Acts as a preservative.\n",
        "    - **Density**: Relates to the sugar content, as sugar is denser than alcohol. Often indicates the alcohol and extract content.\n",
        "    - **pH**: Measures the acidity or basicity of the wine, on a scale of 0 (very acidic) to 14 (very basic). Most wines are between 3-4 pH.\n",
        "    - **Sulphates**: A wine additive which contributes to the sulfur dioxide levels and acts as an antimicrobial and antioxidant agent, enhancing shelf life.\n",
        "    - **Alcohol**: The percentage of alcohol content by volume. Higher alcohol content generally leads to a fuller-bodied wine.\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HLAEAHnspdj",
        "outputId": "c5ea5194-da4d-4046-808e-a4150b85308d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n"
          ]
        }
      ],
      "source": [
        "!kill $(pgrep ngrok)  # kills all running ngrok tunnels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svfFPBbzegY0",
        "outputId": "17a8ed67-c200-480a-9a48-ea70ceb68705"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "import os\n",
        "os.system(\"pkill ngrok\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-14UR0V3kfKW",
        "outputId": "d0178296-427a-47ad-e52d-1881e48118ae"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok version 3.24.0\n",
            "pyngrok version 7.2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur0D1WUReBqa",
        "outputId": "bcbd3a6a-2a95-4353-e035-b9326ff81a61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Open this link: NgrokTunnel: \"https://3a5fbb6727bf.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token(\"30EZrHcoeMzSxVkNjJp3MnE3GUc_7YtZMyb5hN3AjbD4xKyEJ\")\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Open this link:\", public_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRrOzepUtAhj",
        "outputId": "9f781614-c312-463f-94fb-859770bfeb8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.86.186.158:8501\u001b[0m\n",
            "\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/content/app.py:185: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=list(models_comparison.values()), y=list(models_comparison.keys()), ax=ax3, palette='viridis')\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/content/app.py:185: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=list(models_comparison.values()), y=list(models_comparison.keys()), ax=ax3, palette='viridis')\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/content/app.py:185: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=list(models_comparison.values()), y=list(models_comparison.keys()), ax=ax3, palette='viridis')\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/content/app.py:185: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=list(models_comparison.values()), y=list(models_comparison.keys()), ax=ax3, palette='viridis')\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/content/app.py:185: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=list(models_comparison.values()), y=list(models_comparison.keys()), ax=ax3, palette='viridis')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-07-22T16:10:47+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-910eb5a4-4e24-442a-9f64-3c115afd0223 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-07-22T16:10:47+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8501-910eb5a4-4e24-442a-9f64-3c115afd0223 err=\"failed to start tunnel: session closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py &\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}